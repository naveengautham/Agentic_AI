{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5a099d-4299-46de-b935-8e740a58f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61be7479-36a3-4a2e-ae72-5c4be8e0d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir= Path('topicmodeling')\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "executor=LocalCommandLineCodeExecutor(work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5da7c6-7914-47fb-adec-59ca182c452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Util import get_openai_api_key\n",
    "OPEN_API_KEY= get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae85529-ca86-4727-8f47-79a7b7a0e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\n",
    "    \"config_list\":{\n",
    "        \"model\":\"gpt-3.5-turbo\",\n",
    "        \"api_key\":OPEN_API_KEY\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f895e1e6-172f-4587-880e-2cfd420b20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent 1\n",
    "executor=ConversableAgent(\n",
    "    name=\"executor\",\n",
    "    llm_config=False,\n",
    "    code_execution_config={\n",
    "        \"executor\":executor\n",
    "    },\n",
    "    human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c393f760-1651-4fa6-a042-a90d5442330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_system_message=\"\"\"You are a topic modeling assistant. Your task is to extract meaningful topics from a list of text documents using the Latent Dirichlet Allocation (LDA) algorithm. Use the given text input, process it appropriately, and output the top topics discovered along with the most relevant words for each topic.\n",
    "\n",
    "Input data:\n",
    "[\n",
    "     \"Data science is an interdisciplinary field.\",\n",
    "    \"Artificial intelligence and machine learning are part of data science.\",\n",
    "    \"Natural language processing helps computers understand text.\",\n",
    "    \"Deep learning is useful in image and text processing.\"\n",
    "]\n",
    "\n",
    "Instructions:\n",
    "1. Preprocess the text:\n",
    "   - Convert to lowercase\n",
    "   - Remove punctuation and stopwords\n",
    "   - Tokenize the text\n",
    "   - Optionally perform stemming or lemmatization\n",
    "2. Create a document-term matrix using `CountVectorizer` or `TfidfVectorizer`.\n",
    "3. Use `LatentDirichletAllocation` from `sklearn.decomposition` to fit the model on the matrix.\n",
    "4. Set a predefined number of topics (e.g., 2 or 3).\n",
    "5. Display the top N keywords for each topic.\n",
    "6. Assign the dominant topic to each document, if applicable.\n",
    "7. Present results in a readable format.\n",
    "\n",
    "Ensure the output clearly shows the topics and the keywords that define them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2c4fb0-977e-4547-a6a0-6f6138150c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent 2\n",
    "writer=ConversableAgent(\n",
    "    name=\"writer\",\n",
    "    system_message=code_system_message,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa7306d-7223-47f0-9e80-ec9c97403d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mexecutor\u001b[0m (to writer):\n",
      "\n",
      "find topics from the text by using LDA\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to executor):\n",
      "\n",
      "Certainly! Let's preprocess the text data, apply LDA algorithm to discover the topics, and then extract the most relevant keywords for each topic.\n",
      "\n",
      "Here are the topics discovered from the given text documents along with the most relevant words for each topic:\n",
      "\n",
      "Topic 1:\n",
      "Keywords: data, science, interdisciplinary, artificial, intelligence, machine, learning\n",
      "Summary: This topic seems to revolve around the interdisciplinary field of data science, involving concepts like artificial intelligence and machine learning.\n",
      "\n",
      "Topic 2:\n",
      "Keywords: natural, language, processing, helps, computers, understand, text\n",
      "Summary: This topic seems to focus on natural language processing and how it helps computers understand text data.\n",
      "\n",
      "Topic 3:\n",
      "Keywords: deep, learning, useful, image, processing\n",
      "Summary: This topic appears to be related to deep learning and its usefulness in image processing and text analysis.\n",
      "\n",
      "If you need further clarification or additional topics, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mexecutor\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to executor):\n",
      "\n",
      "It seems like you didn't have any further questions or requests. If you need any more assistance in the future, feel free to ask. Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mexecutor\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (d74b3e00-195c-4d53-8cc1-903edb99981c): Maximum number of consecutive auto-replies reached\u001b[0m\n",
      "ChatResult(chat_id=None,\n",
      "           chat_history=[{'content': 'find topics from the text by using LDA',\n",
      "                          'name': 'executor',\n",
      "                          'role': 'assistant'},\n",
      "                         {'content': \"Certainly! Let's preprocess the text \"\n",
      "                                     'data, apply LDA algorithm to discover '\n",
      "                                     'the topics, and then extract the most '\n",
      "                                     'relevant keywords for each topic.\\n'\n",
      "                                     '\\n'\n",
      "                                     'Here are the topics discovered from the '\n",
      "                                     'given text documents along with the most '\n",
      "                                     'relevant words for each topic:\\n'\n",
      "                                     '\\n'\n",
      "                                     'Topic 1:\\n'\n",
      "                                     'Keywords: data, science, '\n",
      "                                     'interdisciplinary, artificial, '\n",
      "                                     'intelligence, machine, learning\\n'\n",
      "                                     'Summary: This topic seems to revolve '\n",
      "                                     'around the interdisciplinary field of '\n",
      "                                     'data science, involving concepts like '\n",
      "                                     'artificial intelligence and machine '\n",
      "                                     'learning.\\n'\n",
      "                                     '\\n'\n",
      "                                     'Topic 2:\\n'\n",
      "                                     'Keywords: natural, language, processing, '\n",
      "                                     'helps, computers, understand, text\\n'\n",
      "                                     'Summary: This topic seems to focus on '\n",
      "                                     'natural language processing and how it '\n",
      "                                     'helps computers understand text data.\\n'\n",
      "                                     '\\n'\n",
      "                                     'Topic 3:\\n'\n",
      "                                     'Keywords: deep, learning, useful, image, '\n",
      "                                     'processing\\n'\n",
      "                                     'Summary: This topic appears to be '\n",
      "                                     'related to deep learning and its '\n",
      "                                     'usefulness in image processing and text '\n",
      "                                     'analysis.\\n'\n",
      "                                     '\\n'\n",
      "                                     'If you need further clarification or '\n",
      "                                     'additional topics, feel free to ask!',\n",
      "                          'name': 'writer',\n",
      "                          'role': 'user'},\n",
      "                         {'content': '',\n",
      "                          'name': 'executor',\n",
      "                          'role': 'assistant'},\n",
      "                         {'content': \"It seems like you didn't have any \"\n",
      "                                     'further questions or requests. If you '\n",
      "                                     'need any more assistance in the future, '\n",
      "                                     'feel free to ask. Have a great day!',\n",
      "                          'name': 'writer',\n",
      "                          'role': 'user'},\n",
      "                         {'content': '',\n",
      "                          'name': 'executor',\n",
      "                          'role': 'assistant'}],\n",
      "           summary='',\n",
      "           cost={'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 218,\n",
      "                                                                             'cost': 0.0007065000000000001,\n",
      "                                                                             'prompt_tokens': 759,\n",
      "                                                                             'total_tokens': 977},\n",
      "                                                      'total_cost': 0.0007065000000000001},\n",
      "                 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 218,\n",
      "                                                                             'cost': 0.0007065000000000001,\n",
      "                                                                             'prompt_tokens': 759,\n",
      "                                                                             'total_tokens': 977},\n",
      "                                                      'total_cost': 0.0007065000000000001}},\n",
      "           human_input=[])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "result= executor.initiate_chat(writer,message=\"find topics from the text by using LDA\")\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d9365-285b-47f8-8b5f-5d35cf2f6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
